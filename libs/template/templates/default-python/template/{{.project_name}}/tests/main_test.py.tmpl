{{/*
  The below works around a problematic error message from Databricks Connect.
  The standard SparkSession is supported in all configurations (workspace, IDE,
  all runtime versions, CLI). But on the CLI it currently gives a confusing
  error message if SPARK_REMOTE is not set. Here we import the DatabricksSession
  as SparkSession so the rest of the code looks as expected.
*/}}
from databricks.connect import DatabricksSession as SparkSession
from pytest import fixture
from {{.project_name}} import main


@fixture(scope="session")
def spark():
    # Create a new Databricks Connect session. If this fails, you should
    # check that you have configured Databricks Connect correctly.
    # See https://docs.databricks.com/dev-tools/databricks-connect.html.
    spark = SparkSession.builder.getOrCreate()
    yield spark
    spark.stop()


def test_main(spark: SparkSession):
    taxis = main.get_taxis(spark)
    assert taxis.count() > 5
